{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     69\u001b[0m Delta \u001b[38;5;241m=\u001b[39m get_Delta(Delta_incomplete)\n\u001b[0;32m---> 70\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarities(\u001b[43mget_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDelta\u001b[49m\u001b[43m)\u001b[49m, Delta)\n\u001b[1;32m     71\u001b[0m cos_utility \u001b[38;5;241m=\u001b[39m cosine_utility(cosine_similarities)\n\u001b[1;32m     72\u001b[0m cos_loss \u001b[38;5;241m=\u001b[39m cosine_difference_loss(cosine_similarities)\n",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m, in \u001b[0;36mget_gradient\u001b[0;34m(Delta)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gradient\u001b[39m(Delta):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m Delta\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (n, k), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelta should have shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n,\u001b[38;5;250m \u001b[39mk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m     utilities_per_amm \u001b[38;5;241m=\u001b[39m \u001b[43mutilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDelta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     gradients_per_amm \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mutilities\u001b[0;34m(Delta)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Delta\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (n, k), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelta should have shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n,\u001b[38;5;250m \u001b[39mk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate adjustments for the last AMM as the negation of the sum of the others\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m new_quantities \u001b[38;5;241m=\u001b[39m \u001b[43minitial_quantities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDelta\u001b[49m\n\u001b[1;32m     27\u001b[0m products \u001b[38;5;241m=\u001b[39m new_quantities\u001b[38;5;241m.\u001b[39mprod(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Product of token quantities in each AMM\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m products\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "n = 2\n",
    "k = 2\n",
    "\n",
    "\n",
    "quantities = [[10, 20, 10], [60, 40, 100], [100, 150, 190], [5, 1, 2], [1000, 1500, 2000]]  # Example initial quantities for each AMM\n",
    "initial_quantities = torch.tensor(quantities, requires_grad=False)\n",
    "\n",
    "# Define Delta for the first n-1 AMMs only, since the last one will be derived\n",
    "Delta_incomplete = torch.zeros((n-1, k), requires_grad=True)\n",
    "\n",
    "def get_Delta(Delta_incomplete):\n",
    "    assert Delta_incomplete.shape == (n-1, k), f\"Delta_incomplete should have shape {(n-1, k)}\"\n",
    "    last_row_adjustment = -torch.sum(Delta_incomplete, axis=0, keepdims=True)\n",
    "    # Combine adjustments to get the full Delta matrix\n",
    "    return torch.cat((Delta_incomplete, last_row_adjustment), axis=0)\n",
    "\n",
    "# Objective function considering the new Delta definition\n",
    "def utilities(Delta):\n",
    "    assert Delta.shape == (n, k), f\"Delta should have shape {(n, k)}\"\n",
    "    # Calculate adjustments for the last AMM as the negation of the sum of the others\n",
    "    new_quantities = initial_quantities + Delta\n",
    "    products = new_quantities.prod(dim=1)  # Product of token quantities in each AMM\n",
    "    return products\n",
    "\n",
    "# get the gradient of utility w.r.t Delta\n",
    "def get_gradient(Delta):\n",
    "    assert Delta.shape == (n, k), f\"Delta should have shape {(n, k)}\"\n",
    "    utilities_per_amm = utilities(Delta)\n",
    "    gradients_per_amm = []\n",
    "    for i in range(n):\n",
    "        if i < n - 1:\n",
    "            grad = torch.autograd.grad(utilities_per_amm[i], Delta_incomplete[i], retain_graph=True)[0]\n",
    "        else:\n",
    "            # For the last AMM, compute gradient with respect to the negation of the sum of previous Deltas\n",
    "            grad = torch.autograd.grad(utilities_per_amm[i], Delta_incomplete, retain_graph=True)[0]\n",
    "            grad = -torch.sum(grad, dim=0)  # Sum and negate to get the gradient for the last row\n",
    "        gradients_per_amm.append(grad)\n",
    "\n",
    "    return torch.stack(gradients_per_amm)\n",
    "    # this has shape (n, k)\n",
    "\n",
    "def cosine_utility(cosine_similarities):\n",
    "    return cosine_similarities.sum()\n",
    "\n",
    "def cosine_difference_loss(cosine_similarities):\n",
    "    return cosine_similarities.var()\n",
    "\n",
    "def cosine_similarities(grads, Delta):\n",
    "    assert grads.shape == (n, k), f\"grads should have shape {(n, k)}\"\n",
    "    assert Delta.shape == (n, k), f\"Delta should have shape {(n, k)}\"\n",
    "    cosines = []\n",
    "    for i in range(n):\n",
    "        grad = grads[i]\n",
    "        cos_times_v = torch.dot(grad, Delta[i]) / (torch.linalg.vector_norm(grad))\n",
    "        cosines.append(cos_times_v)\n",
    "    return torch.stack(cosines)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam([Delta_incomplete], lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    Delta = get_Delta(Delta_incomplete)\n",
    "    cos_similarities = cosine_similarities(get_gradient(Delta), Delta)\n",
    "    cos_utility = cosine_utility(cos_similarities)\n",
    "    cos_loss = cosine_difference_loss(cos_similarities)\n",
    "    relu_loss = torch.sum(torch.relu(-initial_quantities - get_Delta(Delta_incomplete)))\n",
    "    loss = 0\n",
    "    loss -= cos_utility\n",
    "    loss += cos_loss\n",
    "    loss += 1000*relu_loss\n",
    "    print(f\"Cos utility: {cos_utility} | Cos loss: {cos_loss} | ReLU loss: {relu_loss}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # if i % 100 == 0:\n",
    "    #     print(f\"Iteration {i}, loss: {loss.item()}\")\n",
    "\n",
    "    # if i % 100 == 0:\n",
    "    #     print(f\"Utility: {utility}\")\n",
    "    #     print(f\"Delta: {Delta}\")\n",
    "    #     grads = get_gradient(Delta)\n",
    "    #     print(f\"Gradients: {grads}\")\n",
    "    #     cosines = cosine_similarities(grads, Delta)\n",
    "    #     print(f\"Cosine similarities: {cosines}\")\n",
    "    #     print(\"\")\n",
    "\n",
    "final_delta = get_Delta(Delta_incomplete).detach()\n",
    "print(f\"Final Delta: {final_delta}\")\n",
    "print(f\"Final Utility: {utilities(final_delta)}\")\n",
    "print(f\"Final Gradient: {get_gradient(final_delta)}\")\n",
    "print(f\"Final Cosine similarities: {cosine_similarities(get_gradient(final_delta), final_delta)}\")\n",
    "print(f\"Final Cosine utility: {cosine_utility(cosine_similarities(get_gradient(final_delta), final_delta))}\")\n",
    "print(f\"Final Cosine loss: {cosine_difference_loss(cosine_similarities(get_gradient(final_delta), final_delta))}\")\n",
    "print(f\"Final ReLU loss: {torch.sum(torch.relu(-initial_quantities - final_delta))}\")\n",
    "\n",
    "print(f\"Final balances: {initial_quantities + final_delta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
